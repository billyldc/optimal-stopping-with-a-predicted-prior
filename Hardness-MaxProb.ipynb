{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2876d61c-6e6f-48ce-95eb-505eeac4f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from gurobipy import *\n",
    "from json import loads\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd12d9a-b32d-4a61-bfab-adbd1665ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distributions:\n",
    "    \"\"\"\n",
    "    Represents a family of tail-truncated probability distributions.\n",
    "\n",
    "    This class partitions a base distribution into multiple truncated versions,\n",
    "    including a designated prior, and computes normalization constants and\n",
    "    probability mass functions accordingly.\n",
    "\n",
    "    Attributes:\n",
    "        v (list of float): Support values of the base distribution.\n",
    "        p (list of float): Probability masses corresponding to `v`.\n",
    "        indices (list of int): Truncation indices for each distribution.\n",
    "        cum_p_partition (list of float): Cumulative probabilities for each partition.\n",
    "        v_partition (list of int): Maps each support value to its partition index.\n",
    "        K (int): Total number of distributions.\n",
    "        k_star (int): Index of the prior distribution in the sorted list of `indices`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, probs, values = None, indices = None, prior_index = None):\n",
    "        \"\"\"\n",
    "        Initializes the Distributions object with truncated probability distributions.\n",
    "    \n",
    "        Args:\n",
    "            probs (list of float): Nonnegative probability masses corresponding to `values`.\n",
    "            values (list of float): Strictly increasing nonnegative values representing the support. \n",
    "                                    If None, values is set to np.arange(1, len(probs)+1, 1).\n",
    "            indices (list of int): Truncation indices for each distribution. If None, indices is set to list(range(len(values))).\n",
    "            prior_index (int): Truncation index for the prior distribution. If None, prior_index is set to 0.\n",
    "    \n",
    "        Raises:\n",
    "            ValueError: If any input fails validation checks.\n",
    "        \"\"\"        \n",
    "        if not all(p >= 0 for p in probs):\n",
    "            raise ValueError(\"All probs must be nonnegative.\")\n",
    "\n",
    "        if values is not None and not all(v >= 0 for v in values):\n",
    "            raise ValueError(\"All values must be nonnegative.\")\n",
    "        if values is not None and not all(values[i] < values[i + 1] for i in range(len(values) - 1)):\n",
    "            raise ValueError(\"Values must be strictly increasing.\")\n",
    "        if values is not None and len(probs) != len(values):\n",
    "            raise ValueError(\"Values must have the same length as probs.\")\n",
    "        \n",
    "        if indices is not None and not all(isinstance(index, int) and 0 <= index < len(probs) for index in indices):\n",
    "            raise ValueError(\"Indices must be nonnegative integers between 0 and len(probs) - 1.\")\n",
    "        \n",
    "        if prior_index is not None and not (isinstance(prior_index, int) and 0 <= prior_index < len(probs)):\n",
    "            raise ValueError(\"Prior index must be an integer between 0 and len(probs) - 1.\")\n",
    "\n",
    "        sum_probs = sum(probs)\n",
    "        probs = [_/sum_probs for _ in probs]\n",
    "        self.p = probs\n",
    "        if (values is None):\n",
    "            self.v = np.arange(1, len(probs)+1, 1)\n",
    "        else:\n",
    "            self.v = values\n",
    "        if (indices is None):\n",
    "            self.indices = sorted(list(range(len(probs))), reverse=True)\n",
    "        else:\n",
    "            self.indices = sorted(set(indices+[prior_index]), reverse=True)\n",
    "        self.K = len(self.indices)\n",
    "        if (prior_index is None):\n",
    "            self.k_star = 0\n",
    "        else:\n",
    "            self.k_star = self.indices.index(prior_index)\n",
    "        self.v_partition = []\n",
    "        p_partition = [0] * self.K\n",
    "        l = 0\n",
    "        for i in range(len(self.v)-1, -1, -1):\n",
    "            if (l+1 <= len(self.indices)-1 and self.indices[l+1] == i):\n",
    "                l += 1\n",
    "            self.v_partition.insert(0,l)\n",
    "            p_partition[l] += self.p[i]\n",
    "        self.cum_p_partition = np.cumsum(p_partition[::-1])[::-1].tolist() + [0.0]\n",
    "\n",
    "    def summarize(self, sigfig = 5):\n",
    "        \"\"\"\n",
    "        Prints a summary of the distributions, including support and normalized PMFs.\n",
    "    \n",
    "        Args:\n",
    "            sigfig (int): Number of significant figures to display.\n",
    "        \"\"\"\n",
    "        print(\"Summary of distributions (*prior):\")\n",
    "        print(f\"Support:\\n    {[float(f'{v:.{sigfig}g}') for v in self.v]}\")\n",
    "        print(\"PMF:\")\n",
    "        for k in range(self.K):\n",
    "            c_ = self.c(k)\n",
    "            print(f\"{'*' if k == self.k_star else ' '}{k}:\", end=\" \")\n",
    "            print(\n",
    "                [float(f'{p*c_:.{sigfig}g}')*(i <= self.indices[k])\n",
    "                 for i, p in enumerate(self.p)]\n",
    "            )\n",
    "        print('\\n')\n",
    "            \n",
    "    def I(self, x):\n",
    "        \"\"\"\n",
    "        Returns the partition index for a given value or index.\n",
    "    \n",
    "        Args:\n",
    "            x (int or list of int): Index or list of indices to evaluate.\n",
    "    \n",
    "        Returns:\n",
    "            int: Partition index corresponding to `x`.\n",
    "        \"\"\"\n",
    "        if (x is None):\n",
    "            return self.K - 1\n",
    "        if (type(x) == int):\n",
    "            return self.v_partition[x]\n",
    "        return self.v_partition[max(x)]\n",
    "\n",
    "    def c(self, k):\n",
    "        \"\"\"\n",
    "        Returns the normalization constant for distribution `k`.\n",
    "    \n",
    "        Args:\n",
    "            k (int): Distribution index.\n",
    "    \n",
    "        Returns:\n",
    "            float: Inverse of cumulative probability for partition `k`.\n",
    "        \"\"\"\n",
    "        return 1/self.cum_p_partition[k]\n",
    "\n",
    "    def P(self, t, l, mode):\n",
    "        \"\"\"\n",
    "        Computes the probability of a sequence being in a given state under distribution `0`.\n",
    "    \n",
    "        Args:\n",
    "            t (int): Sequence length.\n",
    "            l (int): Partition index.\n",
    "            mode (str): Either \">=\" or \"==\", specifying the condition.\n",
    "    \n",
    "        Returns:\n",
    "            float: Computed probability based on the mode.\n",
    "\n",
    "            - If mode is \">=\":\n",
    "                Returns the probability that the largest of `t` elements \n",
    "                fall within partition `l` or higher.\n",
    "\n",
    "            - If mode is \"==\":\n",
    "                Returns the probability that the largest of `t` elements \n",
    "                fall exactly within partition `l`.\n",
    "\n",
    "            - If `t == 0`:\n",
    "                - For \">=\": Always returns 1 (empty sequence is trivially valid).\n",
    "                - For \"==\": Returns 1 if `l` is the last partition (`K - 1`), else 0.\n",
    "    \n",
    "        Raises:\n",
    "            ValueError: If `mode` is not recognized.\n",
    "        \"\"\"\n",
    "        if (mode == \">=\"):\n",
    "            if (t == 0):\n",
    "                return 1\n",
    "            return self.cum_p_partition[l]**t\n",
    "        if (mode == \"==\"):\n",
    "            if (t == 0):\n",
    "                return (1 if l == self.K-1 else 0)\n",
    "            return self.cum_p_partition[l]**t - self.cum_p_partition[l+1]**t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d0ede4-4dbc-4d81-a107-84a0a2bff7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LP_maxprob:\n",
    "    \"\"\"\n",
    "    Constructs and solves a linear programming model to optimize consistency and robustness \n",
    "    in a sequence of truncated probability distributions using Gurobi.\n",
    "\n",
    "    This model evaluates the trade-off between two metrics—alpha (consistency) and beta (robustness)— \n",
    "    based on a given family of truncated distributions and sequence length.\n",
    "\n",
    "    Attributes:\n",
    "        n (int): Length of the arrival sequence.\n",
    "        F (Distributions): Instance of the Distributions class representing the truncated distributions.\n",
    "        model (gurobipy.Model): Gurobi optimization model.\n",
    "        alpha (float or None): Consistency parameter (or `None` if optimized).\n",
    "        beta (float or None): Robustness parameter (or `None` if optimized).\n",
    "        S (gurobipy.VarDict): Decision variables representing survival probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n, F, alpha, beta, outputflag = 0, monotone = False):\n",
    "        \"\"\"\n",
    "        Initializes the LP model and builds the optimization problem.\n",
    "    \n",
    "        Args:\n",
    "            n (int): Length of the arrival sequence.\n",
    "            F (Distributions): Instance of the Distributions class.\n",
    "            alpha (float or None): Consistency requirement. Must be None if beta is provided.\n",
    "            beta (float or None): Robustness requirement. Must be None if alpha is provided.\n",
    "            outputflag (int): 0 to suppress solver output, 1 to enable it.\n",
    "    \n",
    "        Raises:\n",
    "            ValueError: If `n` is not a positive integer.\n",
    "        \"\"\"\n",
    "        if not (isinstance(n, int) and n > 0):\n",
    "            raise ValueError(\"n must be a positive integer.\")\n",
    "        if not ((alpha is None and isinstance(beta, (float,int)) and 0 <= beta <= 1) or \n",
    "                (isinstance(alpha, (float,int)) and 0 <= alpha <= 1 and beta is None)):\n",
    "            raise ValueError(\"Exactly one of alpha and beta must be None. The other one must be a float or int between 0 and 1.\")\n",
    "        self.n = n\n",
    "        self.F = F\n",
    "        self.model = Model()\n",
    "        self.build(alpha, beta, outputflag)\n",
    "\n",
    "    def build(self, alpha, beta, outputflag = 0):\n",
    "        \"\"\"\n",
    "        Constructs the LP model by defining variables, objective, and constraints.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float or None): Consistency requirement.\n",
    "            beta (float or None): Robustness requirement.\n",
    "            outputflag (int): Gurobi output flag.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If both alpha and beta are provided or both are None.\n",
    "        \"\"\"\n",
    "        self.model.setParam('OutputFlag', outputflag)\n",
    "        self.model.setParam('MIPGap', 1e-9)\n",
    "\n",
    "        # Add decision variables S[t, l] ∈ [0, 1]\n",
    "        self.S = self.model.addVars(list(product(range(self.n+1), range(self.F.K))), lb=0, ub=1, name=\"S\")\n",
    "\n",
    "        # Define objective variable and set optimization direction\n",
    "        if (beta is None):\n",
    "            self.alpha = float(alpha)\n",
    "            self.beta = self.model.addVar(name=\"beta\", lb=0, ub=1)\n",
    "            self.model.setObjective(self.beta, GRB.MAXIMIZE)\n",
    "            print(f\"Given alpha = {self.alpha}, maximizing beta ...\")\n",
    "        else:\n",
    "            self.alpha = self.model.addVar(name=\"alpha\", lb=0, ub=1)\n",
    "            self.beta = float(beta)\n",
    "            self.model.setObjective(self.alpha, GRB.MAXIMIZE)\n",
    "            print(f\"Given beta = {self.beta}, maximizing alpha ...\")\n",
    "\n",
    "        # Add consistency constraint for the prior distribution\n",
    "        self.model.addConstr(self.alpha <= self.ALG(self.F.k_star, self.S), name=f\"consistency_{self.F.k_star}\")\n",
    "\n",
    "        # Add robustness constraint for the prior distribution\n",
    "        for k in self.F.indices:\n",
    "            self.model.addConstr(self.beta <= self.ALG(k, self.S), name=f\"robustness_{k}\")\n",
    "\n",
    "        # Add constraints related to survival and stopping probabilities\n",
    "        for t in range(self.n+1):\n",
    "            for l in range(self.F.K):\n",
    "                if (t == 0): # initial condition for survival probabilities\n",
    "                    self.model.addConstr(self.S[t,l] == (1 if l == self.F.K-1 else 0), name=f\"Exact_{(t,l)}\")\n",
    "                elif (t > 1): # constraints for stopping probabilities\n",
    "                    self.model.addConstr(\n",
    "                        self.S[t,l] * self.F.P(t,l,\"==\") - self.S[t-1,l] * self.F.P(t-1,l,\"==\") * self.F.P(1,l+1,\">=\") >= 0, \n",
    "                        name=f\"R_{(t,l)} <= 1\"\n",
    "                    )\n",
    "                    self.model.addConstr(\n",
    "                        self.S[t,l] * self.F.P(t,l,\"==\") - self.S[t-1,l] * self.F.P(t-1,l,\"==\") * self.F.P(1,l+1,\">=\") \n",
    "                        <= self.F.P(1,l,\"==\") * sum(self.S[t-1,m] * self.F.P(t-1,m,\"==\") for m in range(l, self.F.K)),\n",
    "                        name=f\"R_{(t,l)} >= 0\"\n",
    "                    )\n",
    "                    \n",
    "    def ALG(self, k, S):\n",
    "        \"\"\"\n",
    "        Computes the winning probability for distribution `k`.\n",
    "\n",
    "        The return type depends on the type of `S`:\n",
    "        - If `S` is a Gurobi VarDict, returns a symbolic linear expression (`gurobipy.LinExpr`)\n",
    "        - If `S` is a plain dictionary of floats, returns a numerical value (`float`)\n",
    "    \n",
    "        Args:\n",
    "            k (int): Index of the distribution.\n",
    "            S (dict or gurobipy.VarDict): Dictionary of decision variables representing survival probabilities.\n",
    "    \n",
    "        Returns:\n",
    "            float or gurobipy.LinExpr: Winning probability or its linear expression.\n",
    "        \"\"\"\n",
    "        c = self.F.c(k)\n",
    "        return c**(self.n) * sum(\n",
    "            sum(self.F.P(self.n-t,l,\">=\") * (\n",
    "                sum(S[t-1,m] * self.F.P(t-1,m,\"==\") for m in range(l, self.F.K)) * self.F.P(1,l,\"==\")\n",
    "                + S[t-1,l] * self.F.P(t-1,l,\"==\") * self.F.P(1,l+1,\">=\") - S[t,l] * self.F.P(t,l,\"==\")\n",
    "            )\n",
    "            for l in range(k, self.F.K)\n",
    "                )\n",
    "            for t in range(1, self.n+1)\n",
    "            )\n",
    "    \n",
    "        \n",
    "    def recover_rule(self, S):\n",
    "        \"\"\"\n",
    "        Recovers the stopping rule from the optimized survival probabilities.\n",
    "    \n",
    "        Args:\n",
    "            S (dict): Dictionary of optimized survival probabilities.\n",
    "    \n",
    "        Returns:\n",
    "            dict: Mapping from (t, l) to stopping probabilities.\n",
    "        \"\"\"\n",
    "        R = {}\n",
    "        for t in range(1, self.n+1):\n",
    "            for l in range(self.F.K):\n",
    "                if (t == 1):\n",
    "                    R[t,l] = 1 - S[t,l]\n",
    "                elif (self.F.P(1,l,\"==\") * sum(S[t-1,m] * self.F.P(t-1,m,\"==\") for m in range(l, self.F.K)) > 0):\n",
    "                    R[t,l] = 1 - (\n",
    "                        S[t,l] * self.F.P(t,l,\"==\") - S[t-1,l] * self.F.P(t-1,l,\"==\") * self.F.P(1,l+1,\">=\")\n",
    "                        )/(\n",
    "                            self.F.P(1,l,\"==\") * sum(S[t-1,m] * self.F.P(t-1,m,\"==\") for m in range(l, self.F.K))\n",
    "                        )\n",
    "                else:\n",
    "                    R[t,l] = None\n",
    "        return R\n",
    "    \n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "        Solves the LP model using Gurobi and extracts the optimized values.\n",
    "    \n",
    "        Returns:\n",
    "            tuple:\n",
    "                - S (dict): Optimized state probabilities.\n",
    "                - alpha (float): Optimized or fixed consistency value.\n",
    "                - beta (float): Optimized or fixed robustness value.\n",
    "    \n",
    "        Prints:\n",
    "            Status messages and final optimized values.\n",
    "    \n",
    "        Returns:\n",
    "            (dict, float, float): If successful.\n",
    "            (None, None, None): If optimization fails or model is infeasible.\n",
    "        \"\"\"\n",
    "        self.model.optimize()  \n",
    "        status = self.model.status\n",
    "        if status == GRB.OPTIMAL:\n",
    "            S = {}\n",
    "            for x in self.model.getVars():\n",
    "                if (x.VarName.startswith('S')):\n",
    "                    name = tuple(loads(x.VarName[1:]))\n",
    "                    S[name] = x.X\n",
    "                elif (x.VarName == 'alpha'):\n",
    "                    alpha = x.X\n",
    "                    beta = self.beta\n",
    "                    print(f\"Optimal solution found, alpha * = {alpha}\")\n",
    "                elif (x.VarName == 'beta'):\n",
    "                    beta = x.X\n",
    "                    alpha = self.alpha\n",
    "                    print(f\"Optimal solution found, beta * = {beta}\")\n",
    "            return S, alpha, beta\n",
    "        elif status == GRB.INF_OR_UNBD:\n",
    "            print(\"Model is infeasible or unbounded.\")\n",
    "        elif status == GRB.TIME_LIMIT:\n",
    "            print(\"Time limit reached.\")\n",
    "        elif status == GRB.INTERRUPTED:\n",
    "            print(\"Optimization was interrupted.\")\n",
    "        elif status == GRB.UNBOUNDED:\n",
    "            print(\"Model is unbounded.\")\n",
    "        elif status == GRB.INFEASIBLE:\n",
    "            print(\"Model is infeasible.\")\n",
    "        else:\n",
    "            print(\"Optimization was not successful. Status code:\", status)\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64986b80-9e8a-4e73-84ad-7f688847bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n, p, density):\n",
    "    \"\"\"\n",
    "    Runs a parametric experiment to evaluate the trade-off between consistency (alpha) \n",
    "    and robustness (beta) in a truncated distribution model.\n",
    "\n",
    "    This function initializes a distribution and solves a linear programming model \n",
    "    for a fixed robustness level (`beta = 0`). It then iteratively varies the consistency \n",
    "    parameter `alpha` from a lower bound (0.58) to the maximum feasible value, solving \n",
    "    the model at each step and recording the resulting beta values. Only successful \n",
    "    solutions are retained and plotted.\n",
    "\n",
    "    Args:\n",
    "        n (int): Length of the arrival sequence.\n",
    "        p (list of float): Probability mass function for the base distribution.\n",
    "        density (float): Step size for sampling alpha values between 0.58 and the maximum feasible alpha.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - Alpha_ (list of float): List of alpha values for which the model was successfully solved.\n",
    "            - Beta_ (list of float): Corresponding beta values from the solved models.\n",
    "    \"\"\"\n",
    "    F = Distributions(p)\n",
    "    model = LP_maxprob(n, F, alpha = None, beta = 0, outputflag = 0)\n",
    "    _, max_alpha, _ = model.solve()\n",
    "    Alpha = np.linspace(np.exp(-1), max_alpha, int((max_alpha - np.exp(-1))/density)+2)\n",
    "    Beta = []\n",
    "    solved_set = []\n",
    "    beta = None\n",
    "    for alpha_id, alpha in enumerate(Alpha):\n",
    "        model = LP_maxprob(n, F, alpha, beta, outputflag = 0)\n",
    "        S, a, b = model.solve()\n",
    "        Beta.append(b)\n",
    "        if S is not None:\n",
    "            solved_set.append(alpha_id)\n",
    "    Alpha_ = [alpha for i, alpha in enumerate(Alpha) if i in solved_set]\n",
    "    Beta_ = [beta for i, beta in enumerate(Beta) if i in solved_set]\n",
    "    return Alpha_, Beta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed61aad-7b42-4edd-ae5c-7ddfc966fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 4, m = 6\n",
      "Summary of distributions (*prior):\n",
      "Support:\n",
      "    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "PMF:\n",
      "*0: [0.40816, 0.20408, 0.13605, 0.10204, 0.081633, 0.068027]\n",
      " 1: [0.43796, 0.21898, 0.14599, 0.10949, 0.087591, 0.0]\n",
      " 2: [0.48, 0.24, 0.16, 0.12, 0.0, 0.0]\n",
      " 3: [0.54545, 0.27273, 0.18182, 0.0, 0.0, 0.0]\n",
      " 4: [0.66667, 0.33333, 0.0, 0.0, 0.0, 0.0]\n",
      " 5: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 4   # number of arrivals\n",
    "m = 6   # support size\n",
    "print(f\"n = {n}, m = {m}\")\n",
    "p = [1/i for i in range(1, m+1)]   # relative probability masses (in ascending order of corresponding value)\n",
    "F = Distributions(p)\n",
    "F.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14665f99-83bf-4eba-af0e-ab1deae8a812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2699121\n",
      "Academic license - for non-commercial use only - expires 2026-08-24\n",
      "Given alpha = 0.751, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.6815609473770903\n",
      "Winning probability for distributions:\n",
      "*0: 0.751\n",
      " 1: 0.768992283204936\n",
      " 2: 0.7680847450967678\n",
      " 3: 0.6815609473770903\n",
      " 4: 0.7530864197530865\n",
      " 5: 1.0\n",
      "\n",
      "Optimal survival probabilities:\n",
      "S(0, 0), 0.0\n",
      "S(0, 1), 0.0\n",
      "S(0, 2), 0.0\n",
      "S(0, 3), 0.0\n",
      "S(0, 4), 0.0\n",
      "S(0, 5), 1.0\n",
      "S(1, 0), 0.0\n",
      "S(1, 1), 0.0\n",
      "S(1, 2), 0.0\n",
      "S(1, 3), 1.0\n",
      "S(1, 4), 1.0\n",
      "S(1, 5), 1.0\n",
      "S(2, 0), 0.0\n",
      "S(2, 1), 0.0\n",
      "S(2, 2), 0.0\n",
      "S(2, 3), 0.7889710399543265\n",
      "S(2, 4), 1.0\n",
      "S(2, 5), 1.0\n",
      "S(3, 0), 0.0\n",
      "S(3, 1), 0.0\n",
      "S(3, 2), 0.0\n",
      "S(3, 3), 0.47180992422517853\n",
      "S(3, 4), 0.5263157894736842\n",
      "S(3, 5), 1.0\n",
      "S(4, 0), 0.0\n",
      "S(4, 1), 0.0\n",
      "S(4, 2), 0.0\n",
      "S(4, 3), 0.3163695754272299\n",
      "S(4, 4), 0.30769230769230765\n",
      "S(4, 5), 0.0\n",
      "\n",
      "Optimal stopping probabilities:\n",
      "R(1, 0), 1.0\n",
      "R(1, 1), 1.0\n",
      "R(1, 2), 1.0\n",
      "R(1, 3), 0.0\n",
      "R(1, 4), 0.0\n",
      "R(1, 5), 0.0\n",
      "R(2, 0), 1.0\n",
      "R(2, 1), 1.0\n",
      "R(2, 2), 1.0\n",
      "R(2, 3), 0.38368901826486135\n",
      "R(2, 4), -2.220446049250313e-16\n",
      "R(2, 5), 0.0\n",
      "R(3, 0), 1.0\n",
      "R(3, 1), 1.0\n",
      "R(3, 2), 1.0\n",
      "R(3, 3), 1.0\n",
      "R(3, 4), 1.0000000000000002\n",
      "R(3, 5), -2.220446049250313e-16\n",
      "R(4, 0), 1.0\n",
      "R(4, 1), 1.0\n",
      "R(4, 2), 1.0\n",
      "R(4, 3), 0.9999999999999996\n",
      "R(4, 4), 0.9999999999999998\n",
      "R(4, 5), 1.0\n"
     ]
    }
   ],
   "source": [
    "alpha, beta = 0.751, None     # Try another combination for different result: alpha, beta = None, 0.7\n",
    "model = LP_maxprob(n, F, alpha, beta, outputflag = 0)\n",
    "S, alpha, beta = model.solve()\n",
    "print(\"Winning probability for distributions:\")\n",
    "if S is not None:\n",
    "    for k in range(model.F.K):\n",
    "        print(f\"{'*' if k == model.F.k_star else ' '}{k}: {model.ALG(k, S)}\")\n",
    "        \n",
    "    print(\"\\nOptimal survival probabilities:\")\n",
    "    for key, value in S.items():\n",
    "        print(f\"S{key}, {value}\")\n",
    "    \n",
    "    R = model.recover_rule(S)\n",
    "    print(\"\\nOptimal stopping probabilities:\")\n",
    "    for key, value in R.items():\n",
    "        print(f\"R{key}, {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bb01df-708e-4bb2-9003-de04392969de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 24, m = 200\n",
      "Given beta = 0.0, maximizing alpha ...\n",
      "Optimal solution found, alpha * = 0.5961701228601995\n",
      "Given alpha = 0.36787944117144233, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4364345557718826\n",
      "Given alpha = 0.39070850934031803, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4364345557718826\n",
      "Given alpha = 0.4135375775091938, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4364345557718826\n",
      "Given alpha = 0.4363666456780695, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4364345557718826\n",
      "Given alpha = 0.45919571384694524, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.43324473270837643\n",
      "Given alpha = 0.48202478201582094, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4289866070997483\n",
      "Given alpha = 0.5048538501846966, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4230660238251212\n",
      "Given alpha = 0.5276829183535724, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.4142708936627217\n",
      "Given alpha = 0.5505119865224481, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.3998344235599014\n",
      "Given alpha = 0.5733410546913238, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.3712984784766295\n",
      "Given alpha = 0.5961701228601995, maximizing beta ...\n",
      "Optimal solution found, beta * = 0.06316152416636839\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 24   # number of arrivals\n",
    "m = 200   # support size\n",
    "print(f\"n = {n}, m = {m}\")\n",
    "p = [1/i for i in range(1, m+1)]   # relative probability masses (in ascending order of corresponding value)\n",
    "density = 0.025\n",
    "Alpha, Beta = experiment(n, p, density)\n",
    "plt.plot(Alpha, Beta)\n",
    "plt.plot([0.58, 0.58, np.exp(-1)], [0, np.exp(-1), np.exp(-1)], '-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
